---
title: "Expanding the scope of experimental archaeology using the Perception-Process-Product conceptual framework"
author: 
- Cheng Liu^[Department of Anthropology, Emory University, Atlanta, GA, USA; raylc1996@outlook.com]
abstract: "This paper presents the outline of the Perception-Process-Product ('Triple P') conceptual framework that aims to expand the scope of experimental archaeology. The Triple P framework emphasizes the amplification of multi-level variabilty and the identification of causal relationships of variations across the levels of perception, process, and product. Here we propose the following five basic measures to put the Triple P framework into practice: 1) the acknowledgement of the contribution and limitations of actualistic experiments properly; 2) the normalization the ethological and ethnographic data collection in experimental projects; 3) the involvement of avocational as well as novice participants; 4) the collaboration across labs on a global scale; and 5) the development of an open-access repository for data reuse.  \\par \\textbf{Keywords:} Experimental archaeology; Ethological analysis; Ethnographical analysis; The curse of knowledge; Collaborative knowledge production"
date: "`r Sys.Date()`"
fontsize: 11pt
output: bookdown::pdf_document2
header-includes:
   - \usepackage{textcomp}
   - \usepackage{utopia}
   - \usepackage{lineno}
   - \linenumbers
   - \usepackage{float}
   - \floatplacement{figure}{H}
   - \usepackage{caption}
   - \captionsetup[figure]{font=scriptsize}
   - \captionsetup[table]{font=scriptsize}
linestretch: 1.5
link-citations: yes
linkcolor: blue
bibliography: bibliography.bib
csl: apa.csl
---

\vspace{12pt}

This paper presents the Perception-Process-Product (hereinafter referred to as "Triple P") conceptual framework to expand the scope of experimental archaeology, which tends to center around the reverse engineering of a past technology in a minimal or least-effort manner while ignoring the rich contextual information it affords. Built upon early intellectual principles and practices in behavioral archaeology [@schiffer2010], the Triple P framework aims to **a)** amplify the expression of variability in experimental replicas (product) and their associated behavioral channels (process) as well as sensory experiences (perception) and **b)** better identify the complex interacting relationships across these three levels of variations. To accomplish these two objectives, we advocate the following five measures as integral components of the Triple P framework: 1) acknowledging the contribution and limitations of actualistic experiments properly; 2) normalizing the ethological and ethnographic data collection in experimental projects; 3) encouraging the involvements of avocational as well as novice participants; 4) boosting the collaboration across labs on a global scale; 5) building an open-access repository for data reuse. It is no doubt that strategies of data collection and analysis of a given experimental project should be primarily derived from the research question, which can be legitimately narrow in scope, but the awareness of the rich toolkit available can sometimes inspire researchers to ask questions that are bold and transformative [@schmidt2020]. Here I will mainly leverage the extensive corpus in experimental designs and inferences revolving around stone artifacts to clarify its meaning and demonstrate the necessity and potentials of this framework.

# What good is actualistic experiment?

The now extensive corpus of experimental archaeology have witnessed the growing principally focused on the generation of knowledge regarding the causal mechanism at behavioral level to explain the variation of material culture [@eren2016; @lin2018; @rezek2020; @outram2008; @reynolds1999]. There is no doubt that controlled experiments conducted on stone artifacts [@li2022], particularly those regarding the fracture mechanics [@cotterell1992], provide some foundational and irreplaceable insights on our understanding of the role of lithic technology in prehistory, and unequivocally this line of inquiry should be celebrated and promoted to carry on. Nonetheless, it is oftentimes challenging to directly translate these experimental results into implications of messy human behaviors in the past due to multiple reasons.

Controlled experiments without randomization are not enough to infer causal mechanism, which may be severely biased by factors such as individual differences [@pargeter2023], allocation concealment [@schulz2002], and poor recruitment [@fletcher2012]. Randomized Controlled Trials (RCT) *sensu stricto* as practiced in contemporary medicine and behavioral sciences, known for its high cost [e.g., @speich2019], are extremely rare in experimental archaeology when human participants were involved. Rather, most of our knowledge regarding the past are derived from data sets that can be characterized as Small, Unbalanced, Noisy, but Genuine (SUNG) [@arnaud2023] produced through expeirments featuring small-sized convenience sample. It has also been a debatable issue whether Randomized Controled Trial (RCT) represents the golden standard of knowledge in both philosophy of science [@cartwright2007] and econometrics [@deaton2018].

Trade-off between causality and generalizability in experimental design. For example, in a series of recently published experimental studies aiming at understanding the role of language in the transmission of lithic technologies, standardized procedures like video teaching or using bricks as raw materials are very often. One of the major concerns of experimental archaeology design, as in all empirical social sciences, is the validity, namely how good is a particular conclusion or inference approximates the true condition. The concept of validity has multiple dimensions, and one of the most commonly used classification schemes is internal versus external validity. Roe and Just [@roe2009: 1266-1267] defined internal validity as "the ability of a researcher to argue that observed correlations are causal" and external validity as "the ability to generalize the relationships found in a study to other persons, times, and settings". This balance between these two validity concepts is an issue that cannot be escaped for all experimental archaeology project designs. In the context of stone tool replication, it can be projected into the debate over the use of machines in knapping, a research design that has received increasing attention in the past decades [@eren2016]. Machine knapping is a typical design with high internal validity but low external validity, which has been proved to provides critical insights into lithic fracture mechanics by identifying potential causal variables at the level of individual stone artifact such as determining which angle of blow or how much force of blow will produce the maximal amount of blade area. All the variables of interest are easy to measure, quantify, and control in a machine knapping setting. Nevertheless, being easy to control is not always a virtue as it essentially eliminates the potential interactions between variables operable in the past and thereby providing misleading results when answering archaeological questions. In addition to the applications of machine knapping, the same problem is also incurred by the introduction of standardized artificial material like bricks or video instruction in teaching experiments. As a rule of thumb, external validity should be given more weight in the design when the research focuses on the behaviors of the users of artifacts while internal validity matters more when it comes to the properties of artifacts themselves.

In the past decades, actualistic experiments becomes more common [@liu2022]. Variability as revealed in experiment is crucial and cannot be simply replaced by ethnographic records because the many paleolithic technological components are not displayed in contemporary non-industrial societies, which usually feature technological systems with ground stone artifacts as the target products [@stout2002; @arthur2018]. Statistical techniques for developing causal inference from observational data has also been greatly boosted in recent years [@cunningham2021; @hernan2023].

Experimental archaeology is based on the concept of analogy (i.e., the past is at least partially similar to the present in some aspects). It is acknowledged that the validity of this type of analogical inference has long been a subject of debate in archaeology [@wylie1985; @chapman2016], and a comprehensive review of it is beyond the scope of this essay. For instance, presumably in the paleolithic period the development of stone knapping skills mostly happened during childhood and these children grew up in an environment surrounded by habitual stone tool users and makers. In this case, what can knapping teaching experiments involving modern adults who have zero exposure to stone tools inform us about the past learning behavior? It is important to clarify that no experimental project ever intends or claims to provide the perfect reconstruction of the past but rather aims at identifying variables relevant to the question of interest [@stoutSkillLearningHuman2015], which can be often ignored through pure deductive reasoning. In the end, all experiments are wrong, but some are useful, and we need more of them.

# The ethology and ethnography of stone toolmaking

As implied in its name, the implementation of Triple P framework involves the collection of process-level (ethological) and perception-level (ethnographic) data (**Figure** \@ref(fig:concept)), which is critical to address equifinality and multifinality [@hiscock2004; @premoEquifinalityExplanationThoughts2010], two daunting challenges in archaeological inference that partially contributed to the discipline-wide paradigm shift in the 1980s [@lake2014: 264-265]. Equifinality refers to the phenomenon where a similar state or consequence can be achieved through multiple different paths, while multifinality emerges when a similar process can lead to multiple ends. While we cannot fully solve these two problems and accurately reconstruct the past behavioral processes and intentionality simply based on materials remains, context-rich experiments involving the collection of ethological and ethnographic data can help us better document an enlarged range of possible combinations of variation at these three levels and thereby evaluate the probability of certain behavioral mechanisms behind a given archaeological assemblage.

```{r concept, echo=FALSE, out.width = '80%', fig.align='center', fig.cap="A schematic diagram demonstrating how to operationalize the Perception-Process-Product conceptual framework."}
knitr::include_graphics(here::here("figure/Fig1.jpg"))
```

While formal ethological methods that are widely used in the description and analysis of non-human animal behavior [@fragaszy2018] still largely fall into oblivion among archaeologists, the attempts of reconstructing behavioral sequences involved in the manufacture of material remains are not infrequent. One such example is cognigram, which was first systematically developed and applied in the archaeological research by Haidle [@haidleHowThinkSimple2009; @haidle2010; @lombard2012; @haidle2023]. Cognigram essentially represents an abstracting process of a series of action sequences achieving a similar goal. This approach is a power and elegant yet limited by the curse of expertise [@hinds1999], meaning it cannot handles variability very well. To some extent, it describes the minimal steps to achieve a goal from the perspective of reverse engineering and assume clear causal thinking between each steps in an idealistic manner, while novices often feature a low planning depth [@vanopheusden2023] and a different sets of perception on the causal structure of how certain behaviors will modify the raw materials.

Consequently, we need to accumulate more real-world data by recording a large amount videos of toolmaking and conduct systematical ethogram analysis. With the emergence of new software platforms such as BORIS [@friard2016], the difficulty of coding has decreased significantly in recent years (**Figure** \@ref(fig:ethogram)). Here we use action grammar developed by [@stout2021] as an example. Other coding scheme also exist such as [@mahaney2014], or rotation analysis [@muller2023], or [@cueva-temprana2019].

```{r ethogram, echo=FALSE, out.width = '100%', fig.align='center', fig.cap="An example of coding Bruce Bradley's handaxe knapping session using the action grammer and BORIS software."}
knitr::include_graphics(here::here("figure/Fig2.jpg"))
```

Ethnographies revolving around general archaeological practices [@ethnogra2006], experimental archaeology as a field [@reevesflores2012], as well as practices of specific technologies like flintknapping, including both WEIRD [@whittaker2004] and non-WEIRD populations[@stout2002; @arthur2018], are far from novel. However, it has never been formally recognized as a legitimate research method in experimental archaeology. Echoing with the recent trends of adopting embodied cognition [@varela2017] in archaeological research [@malafouris2013], ethnographic data and methods can reveal hidden information that is otherwise irretrievable and thus should occupy a unique niche in experimental archaeology. This also echoes the post-positivist turn in psychology, a field that is dominated by experimental methods, in the past decades, particularly the emphasis on the value of incorporating qualitative research [@syed2022].

# The curse of knowledge

Contemporary practices in experimental archaeology, as manifested by the fact the the the majority of scholarly publications are produced as results of experiments conducted by single knapper with a dual identity of researcher, tend to be restrained by the cognitive bias known as the "curse of knowledge" or "curse of expertise". The curse of knowledge refers to the phenomenon that it is extremely challenging for experts to ignore the information that is held by them but not others, particularly novices [@hinds1999; @camerer1989]. When the knapping expertise is gradually formed through multiple years of observations and trial-and-error learning, an expert knapper develops some specific ways of strategic planning, motor habits (and their associated impacts on anatomical forms like wrist and elbow), preferences of percussor and raw material types, as well as familiarity of various techniques that become unforgettable. The existence of this cognitive bias is not inherently bad, and these many years of experiences should be appreciated and celebrated by experimental archaeologists. However, what is problematic is that the results of replication experiments conducted by these experienced practitioners, often in settings of single knapper, has been constantly framed as grandiose generalization regarding the evolution of technology and cognition that masks a huge range of technological diversity.

It is more likely for them to come up with ideas that may not be optimal according to the principles of ergonomics. One such example is the the edge angle [@crabtree1977]

Experimental archaeology as a scientific method is rooted in the individualistic reverse engineering in the 19th century instead of inter-generation transmission of knapping knowledge that spans several million years [@flenniken1984; @reevesflores2010; @coles1979; @johnson1978; @whittaker1994: 54-61].

# Many places, many voices

Emphasizing variability at its core, the Triple P conceptual framework inherently adopts an collaborative mode of knowledge production, which has been recently advocated in experimental studies [@ranhorn2020] and museum collection studies [@timbrell2022] of stone artifacts.

In addition to the difficulty in coordination and logistics, the facilitation of large-scale collaborations is often hindered by the current system of research evaluation, where usually only the first author and the senior (last/correspondent) author of a peer-reviewed journal paper will be acknowledged as proper contribution.

# Open science beyond reproducibility

The last step is uploading the data to a open-access repository [@marwick2017]. The building of manufacture can cost [@simon2015; @gilmore2015]. Following the data sharing principles of FAIR [@wilkinson2016] and CARE [@carroll2020]

Given the irreversible nature of archaeological excavations, digitized data, be it text, pictures, or videos, often become the sole evidence that is available for certain research questions. Yet, it has been widely acknowledged that the reuse of archaeological data has not received enough attention among researchers in our discipline (Faniel et al., 2018; Huggett, 2018; Moody et al., 2021). Among many reasons preventing archaeologists from reusing published and digitized data (Sobotkova, 2018), the lack of a standardized practice of and motivation for data sharing is a prominent one (Marwick & Birch, 2018). As stated in the method section, we addressed this issue by sharing the raw data and the code for generating the derived data on an open-access repository. Another major and legitimate concern of archaeological data reuse is their quality. In terms of this aspect, we do acknowledge the limitations of relying on photos when it comes to the more detailed technological analysis of stone artifacts, however, our paper shows that finding the appropriate research questions given the data available is key to revealing new novel insights into the studied topic. Moreover, we believe that this type of research has a strong contemporary relevance due to the continued influence of the COVID-19 on fieldwork-related travel and direct access to archaeological artifacts (Balandier et al., 2022; Ogundiran, 2021).

# Acknowledgements

This study was supported by a research grant from the Leakey Foundation titled "Inferring skill reproduction from stone artifacts: A middle‐range approach" (C. L.).

# References
